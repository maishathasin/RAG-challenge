{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVcVBM0jb2v9"
      },
      "source": [
        "# How to Build a RAG-Powered Chatbot with Chat, Embed, and Rerank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaRTqe1_b2v_"
      },
      "source": [
        "*Read the accompanying [blog post here](https://txt.cohere.com/rag-chatbot).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr-By9oUb2v_"
      },
      "source": [
        "![Feature](https://github.com/cohere-ai/notebooks/blob/main/notebooks/images/rag-chatbot.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQaS3Ok5b2v_"
      },
      "source": [
        "In this notebook, you’ll learn how to build a chatbot that has RAG capabilities, enabling it to connect to external documents, ground its responses on these documents, and produce document citations in its responses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P08HT2MFb2wA"
      },
      "source": [
        "Below is a diagram that provides an overview of what we’ll build, followed by a list of the key steps involved.\n",
        "\n",
        "![Overview](https://github.com/cohere-ai/notebooks/blob/main/notebooks/images/rag-chatbot-flow.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUwdMWGOb2wA"
      },
      "source": [
        "Setup phase:\n",
        "- Step 0: Ingest the documents – get documents, chunk, embed, and index.\n",
        "\n",
        "For each user-chatbot interaction:\n",
        "- Step 1: Get the user message\n",
        "- Step 2: Call the Chat endpoint in query-generation mode\n",
        "- If at least one query is generated\n",
        "    - Step 3: Retrieve and rerank relevant documents\n",
        "    - Step 4: Call the Chat endpoint in document mode to generate a grounded response with citations\n",
        "- If no query is generated\n",
        "    - Step 4: Call the Chat endpoint in normal mode to generate a response\n",
        "\n",
        "Throughout the conversation:\n",
        "- Append the user-chatbot interaction to the conversation thread\n",
        "- Repeat with every interaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sdHJl6LRb2wA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2aaa5a-d352-41c9-b787-f93ee53f227a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.1/275.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install cohere hnswlib unstructured -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DJBNPCH8b2wB"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "import os\n",
        "import hnswlib\n",
        "import json\n",
        "import uuid\n",
        "from typing import List, Dict\n",
        "from unstructured.partition.html import partition_html\n",
        "from unstructured.chunking.title import chunk_by_title\n",
        "api_key = 'UwFTNg2RBH2igiasDxfjimUh1jD7tcQhnJY2sSkK'\n",
        "co = cohere.Client(api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LDFkwr9sb2wB"
      },
      "outputs": [],
      "source": [
        "#@title Enable text wrapping in Google colab\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxF9MiSZb2wC"
      },
      "source": [
        "### Documents component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3e78RaWxb2wC",
        "outputId": "69ae65d6-c762-4f90-a0e6-3fb4b6617701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "class Documents:\n",
        "    \"\"\"\n",
        "    A class representing a collection of documents.\n",
        "\n",
        "    Parameters:\n",
        "    sources (list): A list of dictionaries representing the sources of the documents. Each dictionary should have 'title' and 'url' keys.\n",
        "\n",
        "    Attributes:\n",
        "    sources (list): A list of dictionaries representing the sources of the documents.\n",
        "    docs (list): A list of dictionaries representing the documents, with 'title', 'content', and 'url' keys.\n",
        "    docs_embs (list): A list of the associated embeddings for the documents.\n",
        "    retrieve_top_k (int): The number of documents to retrieve during search.\n",
        "    rerank_top_k (int): The number of documents to rerank after retrieval.\n",
        "    docs_len (int): The number of documents in the collection.\n",
        "    index (hnswlib.Index): The index used for document retrieval.\n",
        "\n",
        "    Methods:\n",
        "    load(): Loads the data from the sources and partitions the HTML content into chunks.\n",
        "    embed(): Embeds the documents using the Cohere API.\n",
        "    index(): Indexes the documents for efficient retrieval.\n",
        "    retrieve(query): Retrieves documents based on the given query.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sources: List[Dict[str, str]]):\n",
        "        self.sources = sources\n",
        "        self.docs = []\n",
        "        self.docs_embs = []\n",
        "        self.retrieve_top_k = 10\n",
        "        self.rerank_top_k = 3\n",
        "        self.load()\n",
        "        self.embed()\n",
        "        self.index()\n",
        "\n",
        "    def load(self) -> None:\n",
        "        \"\"\"\n",
        "        Loads the documents from the sources and chunks the HTML content.\n",
        "        \"\"\"\n",
        "        print(\"Loading documents...\")\n",
        "\n",
        "        for source in self.sources:\n",
        "            elements = partition_html(url=source[\"url\"])\n",
        "            chunks = chunk_by_title(elements)\n",
        "            for chunk in chunks:\n",
        "                self.docs.append(\n",
        "                    {\n",
        "                        \"title\": source[\"title\"],\n",
        "                        \"text\": str(chunk),\n",
        "                        \"url\": source[\"url\"],\n",
        "                    }\n",
        "                )\n",
        "\n",
        "    def embed(self) -> None:\n",
        "        \"\"\"\n",
        "        Embeds the documents using the Cohere API.\n",
        "        \"\"\"\n",
        "        print(\"Embedding documents...\")\n",
        "\n",
        "        batch_size = 90\n",
        "        self.docs_len = len(self.docs)\n",
        "\n",
        "        for i in range(0, self.docs_len, batch_size):\n",
        "            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
        "            texts = [item[\"text\"] for item in batch]\n",
        "            docs_embs_batch = co.embed(\n",
        "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
        "            ).embeddings\n",
        "            self.docs_embs.extend(docs_embs_batch)\n",
        "\n",
        "    def index(self) -> None:\n",
        "        \"\"\"\n",
        "        Indexes the documents for efficient retrieval.\n",
        "        \"\"\"\n",
        "        print(\"Indexing documents...\")\n",
        "\n",
        "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
        "        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
        "        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
        "\n",
        "        print(f\"Indexing complete with {self.idx.get_current_count()} documents.\")\n",
        "\n",
        "    def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Retrieves documents based on the given query.\n",
        "\n",
        "        Parameters:\n",
        "        query (str): The query to retrieve documents for.\n",
        "\n",
        "        Returns:\n",
        "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents, with 'title', 'text', and 'url' keys.\n",
        "        \"\"\"\n",
        "        docs_retrieved = []\n",
        "        query_emb = co.embed(\n",
        "            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
        "        ).embeddings\n",
        "\n",
        "        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
        "\n",
        "        docs_to_rerank = []\n",
        "        for doc_id in doc_ids:\n",
        "            docs_to_rerank.append(self.docs[doc_id][\"text\"])\n",
        "\n",
        "        rerank_results = co.rerank(\n",
        "            query=query,\n",
        "            documents=docs_to_rerank,\n",
        "            top_n=self.rerank_top_k,\n",
        "            model=\"rerank-english-v2.0\",\n",
        "        )\n",
        "\n",
        "        doc_ids_reranked = []\n",
        "        for result in rerank_results:\n",
        "            doc_ids_reranked.append(doc_ids[result.index])\n",
        "\n",
        "        for doc_id in doc_ids_reranked:\n",
        "            docs_retrieved.append(\n",
        "                {\n",
        "                    \"title\": self.docs[doc_id][\"title\"],\n",
        "                    \"text\": self.docs[doc_id][\"text\"],\n",
        "                    \"url\": self.docs[doc_id][\"url\"],\n",
        "                }\n",
        "            )\n",
        "\n",
        "        return docs_retrieved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLzNDxkLb2wD"
      },
      "source": [
        "### Chatbot component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OruYPpTIb2wD",
        "outputId": "7de91169-d38b-4ad1-c848-2d3b3e6fa91a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "class Chatbot:\n",
        "    \"\"\"\n",
        "    A class representing a chatbot.\n",
        "\n",
        "    Parameters:\n",
        "    docs (Documents): An instance of the Documents class representing the collection of documents.\n",
        "\n",
        "    Attributes:\n",
        "    conversation_id (str): The unique ID for the conversation.\n",
        "    docs (Documents): An instance of the Documents class representing the collection of documents.\n",
        "\n",
        "    Methods:\n",
        "    generate_response(message): Generates a response to the user's message.\n",
        "    retrieve_docs(response): Retrieves documents based on the search queries in the response.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, docs: Documents):\n",
        "        self.docs = docs\n",
        "        self.conversation_id = str(uuid.uuid4())\n",
        "\n",
        "    def generate_response(self, message: str):\n",
        "        \"\"\"\n",
        "        Generates a response to the user's message.\n",
        "\n",
        "        Parameters:\n",
        "        message (str): The user's message.\n",
        "\n",
        "        Yields:\n",
        "        Event: A response event generated by the chatbot.\n",
        "\n",
        "        Returns:\n",
        "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
        "\n",
        "        \"\"\"\n",
        "        # Generate search queries (if any)\n",
        "        response = co.chat(message=message, search_queries_only=True)\n",
        "\n",
        "        # If there are search queries, retrieve documents and respond\n",
        "        if response.search_queries:\n",
        "            print(\"Retrieving information...\")\n",
        "\n",
        "            documents = self.retrieve_docs(response)\n",
        "\n",
        "            response = co.chat(\n",
        "                message=message,\n",
        "                documents=documents,\n",
        "                conversation_id=self.conversation_id,\n",
        "                stream=True,\n",
        "            )\n",
        "            for event in response:\n",
        "                yield event\n",
        "\n",
        "        # If there is no search query, directly respond\n",
        "        else:\n",
        "            response = co.chat(\n",
        "                message=message,\n",
        "                conversation_id=self.conversation_id,\n",
        "                stream=True\n",
        "            )\n",
        "            for event in response:\n",
        "                yield event\n",
        "\n",
        "    def retrieve_docs(self, response) -> List[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Retrieves documents based on the search queries in the response.\n",
        "\n",
        "        Parameters:\n",
        "        response: The response object containing search queries.\n",
        "\n",
        "        Returns:\n",
        "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
        "\n",
        "        \"\"\"\n",
        "        # Get the query(s)\n",
        "        queries = []\n",
        "        for search_query in response.search_queries:\n",
        "            queries.append(search_query[\"text\"])\n",
        "\n",
        "        # Retrieve documents for each query\n",
        "        retrieved_docs = []\n",
        "        for query in queries:\n",
        "            retrieved_docs.extend(self.docs.retrieve(query))\n",
        "\n",
        "        # # Uncomment this code block to display the chatbot's retrieved documents\n",
        "        # print(\"DOCUMENTS RETRIEVED:\")\n",
        "        # for idx, doc in enumerate(retrieved_docs):\n",
        "        #     print(f\"doc_{idx}: {doc}\")\n",
        "        # print(\"\\n\")\n",
        "\n",
        "        return retrieved_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAUyiV53b2wD"
      },
      "source": [
        "### App component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z-iCMin3b2wD",
        "outputId": "95e996b5-bf47-403e-fd29-e21961a83448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "class App:\n",
        "    def __init__(self, chatbot: Chatbot):\n",
        "        \"\"\"\n",
        "        Initializes an instance of the App class.\n",
        "\n",
        "        Parameters:\n",
        "        chatbot (Chatbot): An instance of the Chatbot class.\n",
        "\n",
        "        \"\"\"\n",
        "        self.chatbot = chatbot\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Runs the chatbot application.\n",
        "\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            # Get the user message\n",
        "            message = input(\"User: \")\n",
        "\n",
        "            # Typing \"quit\" ends the conversation\n",
        "            if message.lower() == \"quit\":\n",
        "                print(\"Ending chat.\")\n",
        "                break\n",
        "            else:\n",
        "                print(f\"User: {message}\")\n",
        "\n",
        "            # Get the chatbot response\n",
        "            response = self.chatbot.generate_response(message)\n",
        "\n",
        "            # Print the chatbot response\n",
        "            print(\"Chatbot:\")\n",
        "            flag = False\n",
        "            for event in response:\n",
        "                # Text\n",
        "                if event.event_type == \"text-generation\":\n",
        "                    print(event.text, end=\"\")\n",
        "\n",
        "                # Citations\n",
        "                if event.event_type == \"citation-generation\":\n",
        "                    if not flag:\n",
        "                        print(\"\\n\\nCITATIONS:\")\n",
        "                        flag = True\n",
        "                    print(event.citations)\n",
        "\n",
        "            print(f\"\\n{'-'*100}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "116jPdx9b2wE"
      },
      "source": [
        "### Define the documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pfkYz9Qzb2wE",
        "outputId": "93446c72-d015-436d-c3b6-5b90d749d955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define the sources for the documents\n",
        "# As an example, we'll use LLM University's Module 1: What are Large Language Models?\n",
        "# https://docs.cohere.com/docs/intro-large-language-models\n",
        "\n",
        "sources = [\n",
        "    {\n",
        "        \"title\": \"Text Embeddings\",\n",
        "        \"url\": \"https://docs.cohere.com/docs/text-embeddings\"},\n",
        "    {\n",
        "        \"title\": \"Similarity Between Words and Sentences\",\n",
        "        \"url\": \"https://docs.cohere.com/docs/similarity-between-words-and-sentences\"},\n",
        "    {\n",
        "        \"title\": \"The Attention Mechanism\",\n",
        "        \"url\": \"https://docs.cohere.com/docs/the-attention-mechanism\"},\n",
        "    {\n",
        "        \"title\": \"Transformer Models\",\n",
        "        \"url\": \"https://docs.cohere.com/docs/transformer-models\"},\n",
        "    {\n",
        "     \"title\": 'Model summarization',\n",
        "     'url': 'https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/'\n",
        "    },\n",
        "    {\n",
        "        'title': 'Using lime for linear regression',\n",
        "        'url': 'https://christophm.github.io/interpretable-ml-book/lime.html'\n",
        "    },\n",
        "    {\n",
        "        'title': 'Notebook for lime explanability',\n",
        "        'url': 'https://www.kaggle.com/code/prashant111/explain-your-model-predictions-with-lime'\n",
        "    },\n",
        "    {\n",
        "        'title': 'foods with similar tastes',\n",
        "        'url': 'https://www.healthline.com/health/types-of-taste'\n",
        "    },\n",
        "    {\n",
        "        'title': 'Meal database',\n",
        "        'url': 'https://www.themealdb.com/browse/letter/b'\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ym6IC7Xb2wE"
      },
      "source": [
        "### Process the documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8sUcZeDfb2wE",
        "outputId": "eb72f672-6d7b-486a-c9d5-9a2297a9968d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading documents...\n",
            "Embedding documents...\n",
            "Indexing documents...\n",
            "Indexing complete with 260 documents.\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the Documents class with the given sources\n",
        "documents = Documents(sources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjPCjs2Wb2wE"
      },
      "source": [
        "### Run the chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLNeZrx8b2wE",
        "outputId": "093ee4be-c7da-46ec-fd9a-f5440bec2351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: foods with similar tastes than pan bhaji \n",
            "User: foods with similar tastes than pan bhaji \n",
            "Chatbot:\n",
            "Retrieving information...\n",
            "Pan bhaji is a savory dish and humans can recognize savory, or umami, tastes that tend to identify harmful or toxic substances. Other savory foods include meat, cheese, and mushrooms. \n",
            "\n",
            "Would you like to know how to make any of these foods?\n",
            "\n",
            "CITATIONS:\n",
            "[{'start': 52, 'end': 58, 'text': 'savory', 'document_ids': ['doc_1', 'doc_2']}]\n",
            "[{'start': 63, 'end': 68, 'text': 'umami', 'document_ids': ['doc_0']}]\n",
            "[{'start': 90, 'end': 127, 'text': 'identify harmful or toxic substances.', 'document_ids': ['doc_2']}]\n",
            "[{'start': 155, 'end': 183, 'text': 'meat, cheese, and mushrooms.', 'document_ids': ['doc_2']}]\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "User: I am vegetarian\n",
            "User: I am vegetarian\n",
            "Chatbot:\n",
            "Retrieving information...\n",
            "Being vegetarian can be very healthy and there are many options for savory meals that do not contain meat. Would you be open to trying pan bhaji with a vegetarian twist? \n",
            "\n",
            "Other vegetarian foods that pack a similar savory taste to pan bhaji include: \n",
            "\n",
            "- Baingan Bharta, a dish that consists of eggplant that is grilled and mashed and served with spices, tomatoes, and onions. \n",
            "\n",
            "- broccoli and Stilton soup, which is a creamy blend of broccoli and Stilton blue cheese. \n",
            "\n",
            "- Bean and sausage hotpot, which combines beans with savory spices and sausages for a hearty flavor. \n",
            "\n",
            "If you're willing to try a more adventurous dish, why not venture into Asian cuisine with vegan dumplings or Japanese okonomiyaki? \n",
            "\n",
            "Do you have any other questions about adapting dishes to suit your dietary requirements?\n",
            "\n",
            "CITATIONS:\n",
            "[{'start': 254, 'end': 375, 'text': 'Baingan Bharta, a dish that consists of eggplant that is grilled and mashed and served with spices, tomatoes, and onions.', 'document_ids': ['doc_1']}]\n",
            "[{'start': 380, 'end': 467, 'text': 'broccoli and Stilton soup, which is a creamy blend of broccoli and Stilton blue cheese.', 'document_ids': ['doc_1']}]\n",
            "[{'start': 472, 'end': 570, 'text': 'Bean and sausage hotpot, which combines beans with savory spices and sausages for a hearty flavor.', 'document_ids': ['doc_1']}]\n",
            "[{'start': 669, 'end': 678, 'text': 'dumplings', 'document_ids': ['doc_1']}]\n",
            "[{'start': 682, 'end': 702, 'text': 'Japanese okonomiyaki', 'document_ids': ['doc_1']}]\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "User: give me ingredients for these foods\n",
            "User: give me ingredients for these foods\n",
            "Chatbot:\n",
            "Retrieving information...\n",
            "Great, I am happy to provide you with the key ingredients for the foods that suit your tastes. \n",
            "\n",
            "For Baingan Bharta, you would need eggplants, tomatoes, and spices. If you would like to make broccoli and Stilton soup, you will need broccoli, Stilton cheese, and dairy stock. For the Bean and sausage hotpot, you will need beans, savory spices, and vegetarian sausages. \n",
            "\n",
            "Please note that the measurements and additional ingredients might vary depending on the quantity you are cooking for and your desired flavor. \n",
            "\n",
            "Would you like me to help you find recipes for any of these dishes?\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "User: yes\n",
            "User: yes\n",
            "Chatbot:\n",
            "I would be happy to help you find recipes for these delicious-sounding dishes! Here are a few recipes for Baingan Bharta, Broccoli and Stilton Soup, and Bean and Sausage Hotpot that I found for you: \n",
            "\n",
            "1. For Baingan Bharta, you might like this recipe from Tarla Dalal's website. \n",
            "\n",
            "2. For a creamy broccoli and Stilton soup, you could try this recipe from BBC Good Food. \n",
            "\n",
            "3. For a Bean and Sausage Hotpot, you could try this recipe from Vegetarian Times. \n",
            "\n",
            "Please note that these are just a few examples of recipes you can find online for these dishes. You might come across different variations of these dishes based on different cultural styles of cooking as well. \n",
            "\n",
            "Would you like me to help you further by providing more detailed recipes or instructions for any of these dishes?\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "User: Give me foods that have similar tastes like borrito \n",
            "User: Give me foods that have similar tastes like borrito \n",
            "Chatbot:\n",
            "Retrieving information...\n",
            "There are many options for similar-tasting foods to a burrito. It depends if you prefer savory or sweet foods, as I have found options for both. \n",
            "\n",
            "If you're craving something savory, you might like to try: \n",
            "\n",
            "- Baingan Bharta, a vegetarian dish that consists of eggplant that is grilled and mashed with tomatoes and spices. \n",
            "\n",
            "- Bread and Butter Pudding.\n",
            "\n",
            "If you're in the mood for something sweet, you might want to try: \n",
            "\n",
            "- Blackberry Fool.\n",
            "\n",
            "- Banana Pancakes.\n",
            "\n",
            "Again, please note that these are just suggestions and there are many more options out there! Would you like me to continue assisting you with your culinary explorations?\n",
            "\n",
            "CITATIONS:\n",
            "[{'start': 210, 'end': 224, 'text': 'Baingan Bharta', 'document_ids': ['doc_2']}]\n",
            "[{'start': 261, 'end': 269, 'text': 'eggplant', 'document_ids': ['doc_2']}]\n",
            "[{'start': 278, 'end': 296, 'text': 'grilled and mashed', 'document_ids': ['doc_2']}]\n",
            "[{'start': 302, 'end': 322, 'text': 'tomatoes and spices.', 'document_ids': ['doc_2']}]\n",
            "[{'start': 327, 'end': 352, 'text': 'Bread and Butter Pudding.', 'document_ids': ['doc_2']}]\n",
            "[{'start': 424, 'end': 440, 'text': 'Blackberry Fool.', 'document_ids': ['doc_2']}]\n",
            "[{'start': 444, 'end': 460, 'text': 'Banana Pancakes.', 'document_ids': ['doc_2']}]\n",
            "[{'start': 527, 'end': 544, 'text': 'many more options', 'document_ids': ['doc_0', 'doc_2']}]\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the Chatbot class with the Documents instance\n",
        "chatbot = Chatbot(documents)\n",
        "\n",
        "# Create an instance of the App class with the Chatbot instance\n",
        "app = App(chatbot)\n",
        "\n",
        "# Run the chatbot\n",
        "app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmfjOVBgb2wF"
      },
      "outputs": [],
      "source": [
        "Use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6ib00Qtb2wF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-eHh9DFb2wF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_PKnSOsb2wF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjwZ1IMZb2wF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK92BSfAb2wF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tFG32MTb2wF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Prkvlfwcb2wF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqjORp1tb2wF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPg9iTQyb2wF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT9t7YH_b2wF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}