{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEd_QCHW-Xmy"
      },
      "source": [
        "# How to Build a RAG-Powered Chatbot with Chat, Embed, and Rerank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MIYnaLI-Xm6"
      },
      "source": [
        "*Read the accompanying [blog post here](https://txt.cohere.com/rag-chatbot).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD9Yy5d5-Xm8"
      },
      "source": [
        "![Feature](https://github.com/cohere-ai/notebooks/blob/main/notebooks/images/rag-chatbot.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5ZrKPHe-Xm9"
      },
      "source": [
        "In this notebook, you’ll learn how to build a chatbot that has RAG capabilities, enabling it to connect to external documents, ground its responses on these documents, and produce document citations in its responses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ctZrUXQ-Xm_"
      },
      "source": [
        "Below is a diagram that provides an overview of what we’ll build, followed by a list of the key steps involved.\n",
        "\n",
        "![Overview](https://github.com/cohere-ai/notebooks/blob/main/notebooks/images/rag-chatbot-flow.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXWg9g_r-XnA"
      },
      "source": [
        "Setup phase:\n",
        "- Step 0: Ingest the documents – get documents, chunk, embed, and index.\n",
        "\n",
        "For each user-chatbot interaction:\n",
        "- Step 1: Get the user message\n",
        "- Step 2: Call the Chat endpoint in query-generation mode\n",
        "- If at least one query is generated\n",
        "    - Step 3: Retrieve and rerank relevant documents\n",
        "    - Step 4: Call the Chat endpoint in document mode to generate a grounded response with citations\n",
        "- If no query is generated\n",
        "    - Step 4: Call the Chat endpoint in normal mode to generate a response\n",
        "\n",
        "Throughout the conversation:\n",
        "- Append the user-chatbot interaction to the conversation thread\n",
        "- Repeat with every interaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "K1Ke69RX-XnC",
        "outputId": "1feb0883-dc35-4e7f-c5e3-557ed8d60ee5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install cohere hnswlib unstructured lime -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vq9X6SLn-XnG",
        "outputId": "c7c6c95a-1db8-4c26-f248-bdeb5513faff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import cohere\n",
        "import os\n",
        "import hnswlib\n",
        "import json\n",
        "import uuid\n",
        "from typing import List, Dict\n",
        "from unstructured.partition.html import partition_html\n",
        "from unstructured.chunking.title import chunk_by_title\n",
        "\n",
        "import lime\n",
        "import re\n",
        "\n",
        "co = cohere.Client(\"LWOoWCmAD3YSNqSNUG70VgveqeNAs5Q2j3cNcoDD\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lime"
      ],
      "metadata": {
        "id": "nU3gdSdpKCaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import sklearn.ensemble\n",
        "import sklearn.metrics\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5U10ZswcKBnv",
        "outputId": "4abd1fab-03fe-4ce5-f45b-e55df7cc0529"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import sklearn.ensemble\n",
        "import sklearn.metrics\n",
        "from __future__ import print_function\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "categories = ['alt.atheism', 'soc.religion.christian']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
        "class_names = ['atheism', 'christian']\n",
        "\n",
        "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
        "train_vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "test_vectors = vectorizer.transform(newsgroups_test.data)\n",
        "\n",
        "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
        "rf.fit(train_vectors, newsgroups_train.target)\n",
        "\n",
        "\n",
        "prompt = \"Classifying new articles between Atheism and Christianity\"\n",
        "\n",
        "pred = rf.predict(test_vectors)\n",
        "sklearn.metrics.f1_score(newsgroups_test.target, pred, average='binary')\n",
        "\n",
        "\n",
        "from lime import lime_text\n",
        "from sklearn.pipeline import make_pipeline\n",
        "c = make_pipeline(vectorizer, rf)\n",
        "\n",
        "print(c.predict_proba([newsgroups_test.data[0]]))\n",
        "\n",
        "\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n",
        "\n",
        "\n",
        "\n",
        "idx = 83\n",
        "\n",
        "\n",
        "exp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=6)\n",
        "print('Document id: %d' % idx)\n",
        "print('Probability(christian) =', c.predict_proba([newsgroups_test.data[idx]])[0,1])\n",
        "print('True class: %s' % class_names[newsgroups_test.target[idx]])\n",
        "\n",
        "\n",
        "# using output from here\n",
        "exp.as_list()\n",
        "\n",
        "\n",
        "print('Original prediction:', rf.predict_proba(test_vectors[idx])[0,1])\n",
        "tmp = test_vectors[idx].copy()\n",
        "tmp[0,vectorizer.vocabulary_['Posting']] = 0\n",
        "tmp[0,vectorizer.vocabulary_['Host']] = 0\n",
        "print('Prediction removing some features:', rf.predict_proba(tmp)[0,1])\n",
        "print('Difference:', rf.predict_proba(tmp)[0,1] - rf.predict_proba(test_vectors[idx])[0,1])\n",
        "\n",
        "\n",
        "\n",
        "all_explanations = []\n",
        "\n",
        "for idx in range(10):\n",
        "    # Explain the instance\n",
        "    exp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=6)\n",
        "\n",
        "    # Extract the top three feature weights\n",
        "    top_features = sorted(exp.as_list(), key=lambda x: abs(x[1]), reverse=True)[:3]\n",
        "\n",
        "    # Store the results\n",
        "    all_explanations.append({\n",
        "        'probability_christian': c.predict_proba([newsgroups_test.data[idx]])[0,1],\n",
        "        'true_class': class_names[newsgroups_test.target[idx]],\n",
        "        'top_features': top_features\n",
        "    })\n",
        "\n",
        "print(all_explanations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "z7l_KB-zKbFa",
        "outputId": "9513faee-3442-4c17-bb54-5a24537feb67"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.304 0.696]]\n",
            "Document id: 83\n",
            "Probability(christian) = 0.424\n",
            "True class: atheism\n",
            "Original prediction: 0.424\n",
            "Prediction removing some features: 0.682\n",
            "Difference: 0.25800000000000006\n",
            "[{'probability_christian': 0.696, 'true_class': 'christian', 'top_features': [('article', -0.078300159574246), ('au', -0.052026541580377964), ('deleted', -0.023290267290638107)]}, {'probability_christian': 0.662, 'true_class': 'christian', 'top_features': [('morality', -0.0539254567963974), ('alt', -0.024569979106880337), ('atheist', -0.019500083271421782)]}, {'probability_christian': 0.21, 'true_class': 'atheism', 'top_features': [('Keith', -0.10664864563822533), ('Re', -0.07006049475826955), ('California', -0.060473063276174854)]}, {'probability_christian': 0.876, 'true_class': 'christian', 'top_features': [('Christ', 0.025473411718284086), ('rutgers', 0.023079071237483352), ('Christians', 0.022271285304222493)]}, {'probability_christian': 0.406, 'true_class': 'atheism', 'top_features': [('Posting', -0.09878012637601666), ('Host', -0.09680847678503698), ('NNTP', -0.07533066332783248)]}, {'probability_christian': 0.874, 'true_class': 'christian', 'top_features': [('rutgers', 0.03974133447899979), ('1993', 0.021469847417834198), ('Christians', 0.02066359482582359)]}, {'probability_christian': 0.806, 'true_class': 'christian', 'top_features': [('Christ', 0.021196728155797404), ('Re', -0.01753373817698244), ('wrote', -0.014023202564700257)]}, {'probability_christian': 0.804, 'true_class': 'christian', 'top_features': [('News', -0.02064966762189949), ('God', 0.020187484199815288), ('Christ', 0.016919962185192743)]}, {'probability_christian': 0.838, 'true_class': 'christian', 'top_features': [('sgi', -0.028229968915786312), ('Christ', 0.024381672648091147), ('church', 0.01837050641119472)]}, {'probability_christian': 0.452, 'true_class': 'atheism', 'top_features': [('de', -0.06805546408547294), ('writes', -0.06251190681501026), ('article', -0.05223424108500318)]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "HNWrbweP-XnH",
        "outputId": "b9e9f277-af73-47bc-d649-df63bfc4f3a2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Enable text wrapping in Google colab\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OiBa_N0-XnJ"
      },
      "source": [
        "### Documents component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JlQ8j3J1-XnJ",
        "outputId": "fb4935c6-ce6a-4a9b-be85-01673d0effeb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "class Documents:\n",
        "    \"\"\"\n",
        "    A class representing a collection of documents.\n",
        "\n",
        "    Parameters:\n",
        "    sources (list): A list of dictionaries representing the sources of the documents. Each dictionary should have 'title' and 'url' keys.\n",
        "\n",
        "    Attributes:\n",
        "    sources (list): A list of dictionaries representing the sources of the documents.\n",
        "    docs (list): A list of dictionaries representing the documents, with 'title', 'content', and 'url' keys.\n",
        "    docs_embs (list): A list of the associated embeddings for the documents.\n",
        "    retrieve_top_k (int): The number of documents to retrieve during search.\n",
        "    rerank_top_k (int): The number of documents to rerank after retrieval.\n",
        "    docs_len (int): The number of documents in the collection.\n",
        "    index (hnswlib.Index): The index used for document retrieval.\n",
        "\n",
        "    Methods:\n",
        "    load(): Loads the data from the sources and partitions the HTML content into chunks.\n",
        "    embed(): Embeds the documents using the Cohere API.\n",
        "    index(): Indexes the documents for efficient retrieval.\n",
        "    retrieve(query): Retrieves documents based on the given query.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sources: List[Dict[str, str]]):\n",
        "        self.sources = sources\n",
        "        self.docs = []\n",
        "        self.docs_embs = []\n",
        "        self.retrieve_top_k = 10\n",
        "        self.rerank_top_k = 3\n",
        "        self.load()\n",
        "        self.embed()\n",
        "        self.index()\n",
        "\n",
        "    def load(self) -> None:\n",
        "        \"\"\"\n",
        "        Loads the documents from the sources and chunks the HTML content.\n",
        "        \"\"\"\n",
        "        print(\"Loading documents...\")\n",
        "\n",
        "        for source in self.sources:\n",
        "            elements = partition_html(url=source[\"url\"])\n",
        "            chunks = chunk_by_title(elements)\n",
        "            for chunk in chunks:\n",
        "                self.docs.append(\n",
        "                    {\n",
        "                        \"title\": source[\"title\"],\n",
        "                        \"text\": str(chunk),\n",
        "                        \"url\": source[\"url\"],\n",
        "                    }\n",
        "                )\n",
        "\n",
        "    def embed(self) -> None:\n",
        "        \"\"\"\n",
        "        Embeds the documents using the Cohere API.\n",
        "        \"\"\"\n",
        "        print(\"Embedding documents...\")\n",
        "\n",
        "        batch_size = 90\n",
        "        self.docs_len = len(self.docs)\n",
        "\n",
        "        for i in range(0, self.docs_len, batch_size):\n",
        "            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
        "            texts = [item[\"text\"] for item in batch]\n",
        "            docs_embs_batch = co.embed(\n",
        "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
        "            ).embeddings\n",
        "            self.docs_embs.extend(docs_embs_batch)\n",
        "\n",
        "    def index(self) -> None:\n",
        "        \"\"\"\n",
        "        Indexes the documents for efficient retrieval.\n",
        "        \"\"\"\n",
        "        print(\"Indexing documents...\")\n",
        "\n",
        "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
        "        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
        "        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
        "\n",
        "        print(f\"Indexing complete with {self.idx.get_current_count()} documents.\")\n",
        "\n",
        "    def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Retrieves documents based on the given query.\n",
        "\n",
        "        Parameters:\n",
        "        query (str): The query to retrieve documents for.\n",
        "\n",
        "        Returns:\n",
        "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents, with 'title', 'text', and 'url' keys.\n",
        "        \"\"\"\n",
        "        docs_retrieved = []\n",
        "        query_emb = co.embed(\n",
        "            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
        "        ).embeddings\n",
        "\n",
        "        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
        "\n",
        "        docs_to_rerank = []\n",
        "        for doc_id in doc_ids:\n",
        "            docs_to_rerank.append(self.docs[doc_id][\"text\"])\n",
        "\n",
        "        rerank_results = co.rerank(\n",
        "            query=query,\n",
        "            documents=docs_to_rerank,\n",
        "            top_n=self.rerank_top_k,\n",
        "            model=\"rerank-english-v2.0\",\n",
        "        )\n",
        "\n",
        "        doc_ids_reranked = []\n",
        "        for result in rerank_results:\n",
        "            doc_ids_reranked.append(doc_ids[result.index])\n",
        "\n",
        "        for doc_id in doc_ids_reranked:\n",
        "            docs_retrieved.append(\n",
        "                {\n",
        "                    \"title\": self.docs[doc_id][\"title\"],\n",
        "                    \"text\": self.docs[doc_id][\"text\"],\n",
        "                    \"url\": self.docs[doc_id][\"url\"],\n",
        "                }\n",
        "            )\n",
        "\n",
        "        return docs_retrieved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdQIm_cz-XnN"
      },
      "source": [
        "### Chatbot component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9xumyf0r-XnN",
        "outputId": "f0f56d60-f28e-4200-850e-2b7d22f50d5c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "class Chatbot:\n",
        "    \"\"\"\n",
        "    A class representing a chatbot.\n",
        "\n",
        "    Parameters:\n",
        "    docs (Documents): An instance of the Documents class representing the collection of documents.\n",
        "\n",
        "    Attributes:\n",
        "    conversation_id (str): The unique ID for the conversation.\n",
        "    docs (Documents): An instance of the Documents class representing the collection of documents.\n",
        "\n",
        "    Methods:\n",
        "    generate_response(message): Generates a response to the user's message.\n",
        "    retrieve_docs(response): Retrieves documents based on the search queries in the response.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, docs: Documents):\n",
        "        self.docs = docs\n",
        "        self.conversation_id = str(uuid.uuid4())\n",
        "\n",
        "    def generate_response(self, message: str):\n",
        "        \"\"\"\n",
        "        Generates a response to the user's message.\n",
        "\n",
        "        Parameters:\n",
        "        message (str): The user's message.\n",
        "\n",
        "        Yields:\n",
        "        Event: A response event generated by the chatbot.\n",
        "\n",
        "        Returns:\n",
        "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
        "\n",
        "        \"\"\"\n",
        "        # Generate search queries (if any)\n",
        "        response = co.chat(message=message, search_queries_only=True)\n",
        "\n",
        "        # If there are search queries, retrieve documents and respond\n",
        "        if response.search_queries:\n",
        "            print(\"Retrieving information...\")\n",
        "\n",
        "            documents = self.retrieve_docs(response)\n",
        "\n",
        "            response = co.chat(\n",
        "                message=message,\n",
        "                documents=documents,\n",
        "                conversation_id=self.conversation_id,\n",
        "                stream=True,\n",
        "            )\n",
        "            for event in response:\n",
        "                yield event\n",
        "\n",
        "        # If there is no search query, directly respond\n",
        "        else:\n",
        "            response = co.chat(\n",
        "                message=message,\n",
        "                conversation_id=self.conversation_id,\n",
        "                stream=True\n",
        "            )\n",
        "            for event in response:\n",
        "                yield event\n",
        "\n",
        "    def retrieve_docs(self, response) -> List[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Retrieves documents based on the search queries in the response.\n",
        "\n",
        "        Parameters:\n",
        "        response: The response object containing search queries.\n",
        "\n",
        "        Returns:\n",
        "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
        "\n",
        "        \"\"\"\n",
        "        # Get the query(s)\n",
        "        queries = []\n",
        "        for search_query in response.search_queries:\n",
        "            queries.append(search_query[\"text\"])\n",
        "\n",
        "        # Retrieve documents for each query\n",
        "        retrieved_docs = []\n",
        "        for query in queries:\n",
        "            retrieved_docs.extend(self.docs.retrieve(query))\n",
        "\n",
        "        # # Uncomment this code block to display the chatbot's retrieved documents\n",
        "        # print(\"DOCUMENTS RETRIEVED:\")\n",
        "        # for idx, doc in enumerate(retrieved_docs):\n",
        "        #     print(f\"doc_{idx}: {doc}\")\n",
        "        # print(\"\\n\")\n",
        "\n",
        "        return retrieved_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cll0vK1b-XnP"
      },
      "source": [
        "### App component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0Zmtn_99-XnP",
        "outputId": "fe6177c4-779e-4b5c-d29e-c998c4830557"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "class App:\n",
        "    def __init__(self, chatbot: Chatbot):\n",
        "        \"\"\"\n",
        "        Initializes an instance of the App class.\n",
        "\n",
        "        Parameters:\n",
        "        chatbot (Chatbot): An instance of the Chatbot class.\n",
        "\n",
        "        \"\"\"\n",
        "        self.chatbot = chatbot\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Runs the chatbot application.\n",
        "\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            # Get the user message\n",
        "            message = input(\"User: \")\n",
        "\n",
        "            # Typing \"quit\" ends the conversation\n",
        "            if message.lower() == \"quit\":\n",
        "                print(\"Ending chat.\")\n",
        "                break\n",
        "            else:\n",
        "                print(f\"User: {message}\")\n",
        "\n",
        "            # Get the chatbot response\n",
        "            response = self.chatbot.generate_response(message)\n",
        "\n",
        "            # Print the chatbot response\n",
        "            print(\"Chatbot:\")\n",
        "            flag = False\n",
        "            for event in response:\n",
        "                # Text\n",
        "                if event.event_type == \"text-generation\":\n",
        "                    print(event.text, end=\"\")\n",
        "\n",
        "                # Citations\n",
        "                if event.event_type == \"citation-generation\":\n",
        "                    if not flag:\n",
        "                        print(\"\\n\\nCITATIONS:\")\n",
        "                        flag = True\n",
        "                    print(event.citations)\n",
        "\n",
        "            print(f\"\\n{'-'*100}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO8fG6mo-XnT"
      },
      "source": [
        "### Run the chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4nfOOoCE-XnU",
        "outputId": "fd98634b-a47b-4685-aaf2-e6b8a2bb3c36"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "message = \"\"\"I am trying to gain additional context regarding explainablilty of model predictions.\n",
        "                        Can you suggest about 50-100 wikipedia links (just the links)\n",
        "                        that can be helpful in providing more contextual information\n",
        "                        for the following model purpose:\"\"\" + prompt\n",
        "response = co.chat(message=message)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "j8ixMYy7Jm5b",
        "outputId": "e932e7f0-0863-4336-fb25-c9757d895a7b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, here are a few Wikipedia links that might provide some context about the classification of articles between Atheism and Christianity:\n",
            "\n",
            "1. https://en.wikipedia.org/wiki/Atheism\n",
            "2. https://en.wikipedia.org/wiki/Christianity\n",
            "3. https://en.wikipedia.org/wiki/Religion\n",
            "4. https://en.wikipedia.org/wiki/Atheist\n",
            "5. https://en.wikipedia.org/wiki/Agnosticism\n",
            "6. https://en.wikipedia.org/wiki/List_of_atheists\n",
            "7. https://en.wikipedia.org/wiki/List_of_Christians\n",
            "8. https://en.wikipedia.org/wiki/Freethinking\n",
            "9. https://en.wikipedia.org/wiki/Secularism\n",
            "10. https://en.wikipedia.org/wiki/Rational_atheism\n",
            "\n",
            "Note that these links provide a wide range of information, from definitions and distinctions between concepts, to lists of examples and groups relevant to the topic. This variety of sources can help provide a more holistic understanding of the context necessary to classify articles between Atheism and Christianity. \n",
            "\n",
            "Would you like me to provide more focused recommendations based on this preliminary list?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "9Iu1X6FM-XnV",
        "outputId": "c6699ee7-589a-4277-baab-5293c1ec5eec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://en.wikipedia.org/wiki/Atheism',\n",
              " 'https://en.wikipedia.org/wiki/Christianity',\n",
              " 'https://en.wikipedia.org/wiki/Category:Religion_and_philosophy',\n",
              " 'https://en.wikipedia.org/wiki/Category:Belief_systems',\n",
              " 'https://en.wikipedia.org/wiki/Comparison_of_religions',\n",
              " 'https://en.wikipedia.org/wiki/List_of_atheistic_philosophers',\n",
              " 'https://en.wikipedia.org/wiki/List_of_Christian_philosophers',\n",
              " 'https://en.wikipedia.org/wiki/Religion_and_science',\n",
              " 'https://en.wikipedia.org/wiki/Rationalism',\n",
              " 'https://en.wikipedia.org/wiki/Empiricism']"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def extract_links(text):\n",
        "    # Define a regular expression pattern to match URLs\n",
        "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
        "\n",
        "    # Use re.findall() to extract all URLs from the text\n",
        "    links = re.findall(url_pattern, text)\n",
        "\n",
        "    return links\n",
        "\n",
        "extract_links(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KSGzxjXS-XnV",
        "outputId": "cfc6c4e2-8e87-489d-fc19-7b700bdf83a6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def create_dict(links):\n",
        "  res =[]\n",
        "  for link in links:\n",
        "    res.append(\n",
        "        {\n",
        "            'title' : link,\n",
        "            'url' : link\n",
        "        })\n",
        "  return res\n",
        "\n",
        "import requests\n",
        "\n",
        "def filter_urls(url_list):\n",
        "    existing_urls = []\n",
        "\n",
        "    for url in url_list:\n",
        "        try:\n",
        "            response = requests.head(url, allow_redirects=True)\n",
        "            if response.status_code == 200:\n",
        "                existing_urls.append(url)\n",
        "        except requests.RequestException as e:\n",
        "          continue\n",
        "\n",
        "    return existing_urls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "khwJ6KGX-XnV",
        "outputId": "51c9a6b5-ecef-41b0-a03c-d675e271a6b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading documents...\n",
            "Embedding documents...\n",
            "Indexing documents...\n",
            "Indexing complete with 2054 documents.\n"
          ]
        }
      ],
      "source": [
        "links = extract_links(response.text)\n",
        "sources = create_dict(filter_urls(links))\n",
        "documents = Documents(sources)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = \"\"\n",
        "for link in links[:2]:\n",
        "  response = co.chat(message=f'Summarize all the data in this link: {link} in 100 words or less')\n",
        "  summaries+=response.text\n",
        "  print(link)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "9rlZcS8GTuic",
        "outputId": "4727eb7c-2980-4c37-a66b-c70c59d7467c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://en.wikipedia.org/wiki/Atheism\n",
            "https://en.wikipedia.org/wiki/Christianity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KKQMOI12-XnV",
        "outputId": "97c65b04-b798-4144-afa0-5dc821625b27"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create an instance of the Chatbot class with the Documents instance\n",
        "chatbot = Chatbot(documents)\n",
        "\n",
        "final_explanations = \"\"\n",
        "for i in all_explanations:\n",
        "  final_explanations += str(i)\n",
        "\n",
        "message = \"Given a machine learning model with the following purpose: \" + prompt + \"and the following explanations for the features\" + final_explanations + \"can you explain why this model contextually makes sense with the following references: \"   + summaries\n",
        "\n",
        "response = chatbot.generate_response(message=message)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(summaries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "iXNoeWXcY-fs",
        "outputId": "0b4d8550-21cf-450c-86bc-c7dd8f37da95"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2309"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "fbRobYM9-XnW",
        "outputId": "62f1b839-64bb-4672-9ff4-301aca14e56b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving information...\n",
            "This model appears to be a classifier attempting to distinguish between articles likely written from the perspective of an atheist and articles likely written from the perspective of a Christian. \n",
            "\n",
            "Atheism is a disbelief in the existence of deities. More broadly, atheists reject the belief that any deities exist. In this sense, atheists argue that since there is an absence of evidence for the existence of deities, it can be concluded that they do not exist. Atheists often promote the scientific method and empirical evidence as the best ways to understand the universe, and they argue that religious beliefs should be subject to questioning and criticism like any other belief system. \n",
            "\n",
            "Christianity, on the other hand, is based on the teachings of Jesus Christ, who Christians believe to be the Son of God and the savior of humanity. Christians make up a significant portion of the global population and can be found in all parts of the world. Christianity plays a significant role in shaping the cultural, social, and political landscape of many countries and regions. \n",
            "\n",
            "Would you like me to go into more detail about the specific beliefs associated with Christianity and Atheism?"
          ]
        }
      ],
      "source": [
        "for event in response:\n",
        "  try:\n",
        "    if event.event_type =='text-generation':\n",
        "      print(event.text, end=\"\")\n",
        "\n",
        "  except:\n",
        "    continue\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XWmSU-ZZYvuv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}